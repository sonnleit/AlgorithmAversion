---
title: "Algorithm Aversion"
author: "Kopkow, Angermaier, Rohrer, Sonnleitner"
date: "February 2022"
output:
  pdf_document:
    toc: true
    toc_depth: 2
  html_document:
    toc: true
    toc_depth: 2
---





# Motivation: Erwin


# Data retrieval


# Data processing: Mathias

```{r Libraries, message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(tidytext)
library(textdata)
library(dplyr)
library(vader)
library(academictwitteR)
library(data.table)
library(readr)
library(boot)
library(knitr)
```

used libraries

```{r read and group data, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
 alg.data <- read_csv('algtweetsalgData.csv'
                      )

#write.csv(alg.data,"C:/Users/usr/Documents/algtweetsalgData.csv", row.names = TRUE)


alg.data <- alg.data[, c  ("index" ,"text", "id" ,"created_at", "VADER",
                           "VADERclass", "Business" ,  "Social.Media", 
                           "Technology" ,  "Immutability" ,"Influence", 
                           "Application",   "Aversion",
                           "Year","topic" ) ]

alg.data <- select(alg.data, -'topic')

```


```{r sorting, echo=FALSE}
#alg.data %>% group_by(alg.data$topic, alg.data$Year, alg.data$VADERclass) %>% summarise(Sent = #n())-> summ.data
alg.data %>% group_by(alg.data$Year, alg.data$VADERclass) %>% summarise(Sent = n()) -> summ.year
#alg.data %>% group_by(alg.data$topic, alg.data$VADERclass) %>% summarise(Sent = n()) -> summ.topic


#alg.data %>% group_by(topic, Year, VADERclass) %>% summarise(Sent = n()) -> summ.data
alg.data %>% group_by(Year, VADERclass) %>% summarise(Sent = n()) -> summ.year

#adds percentage to yearwise DF
summ.year<- 
  summ.year %>% 
  group_by(Year) %>% 
  mutate(All = sum(Sent),percent=(100*Sent/All))


```

```{r cummulated}
listofdfs <- list()

#data group for cummulated dataframe

for (i in c(7:13)){
  alg.data %>% 
    filter(alg.data[,i]>=1)%>% 
    mutate(Topic = colnames(alg.data)[i], VADERclass=as.factor(VADERclass))%>% 
    group_by(Year,Topic,VADERclass, .drop=FALSE)%>% 
    summarise(Sent = n(), .groups = "drop") ->listofdfs[[i]]
}
summ.cumm <- bind_rows(listofdfs)


#adds percentage to cummulated DF
summ.cumm <- 
  summ.cumm %>% 
  group_by(Topic, Year) %>% 
  mutate(All = sum(Sent),percent=(100*Sent/All))

summ.cumm
```

```{r topic, message=FALSE, warning=FALSE, paged.print=FALSE}
#data group for topic oriented dataframe

listofdfs <- list()

for (i in c(7:13)){
  alg.data %>% 
    filter(alg.data[,i]>=1)%>% 
    mutate(Topic = colnames(alg.data)[i])%>% 
    group_by( VADERclass, Topic) %>% 
    summarise(Sent = n()) ->listofdfs[[i]]
}
summ.topic <- bind_rows(listofdfs)

#adds percentage to topicwise DF
summ.topic<- 
  summ.topic %>% 
  group_by(Topic) %>% 
  mutate(All = sum(Sent),percent=(100*Sent/All))



```

```{r headsum topic}

kable(summ.topic[1:5, ], caption = "Topic Table")
```

```{r wordgrouptest}
#--------------Test wordgroups---------------------
listofdfs <- list()


for (i in c(7:13)){
  alg.data %>% 
    filter(alg.data[,i]>=1)%>% 
    mutate(Topic = colnames(alg.data)[i])%>% 
    sample_n(size = 20)%>% 
  group_by( VADERclass, Topic)  ->listofdfs[[i]]
}
Wordgrouptest<- bind_rows(listofdfs)
```



# Analysis 


A Confidence interval based on 10000 bootstrap replications was calculated. It revealed that with a probability of 95% that the mean value of the sentiment analysis falls between 0.0766 and 0.1349.


```{r bootstrap, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
#--------------Bootstraping---------------------
listofdfs <- list()

## Sample of 100 tweets per topic
for (i in c(7:13)){
  alg.data %>% 
    filter(alg.data[,i]>=1)%>% 
    mutate(Topic = colnames(alg.data)[i])%>% 
    mutate(Neutral = VADERclass=="Neutral")%>% 
    mutate(Positive = VADERclass=="Positive")%>% 
    mutate(Negative = VADERclass=="Negative")%>% 
    mutate(Aversive = VADERclass=="Aversive")%>% 
    sample_n(size = 100)%>% 
    group_by( VADERclass, Topic) ->listofdfs[[i]]
}
bootstrap<- bind_rows(listofdfs)
bootstrap %>% select(Year,Topic,VADER,VADERclass,Neutral,Positive,Negative,Aversive) -> bootstrap
bootstrap 



bootstrap  -> ObservedHeight
ObservedHeights <- ObservedHeight$VADER
  
mean(ObservedHeights)
ReturnMean <- function(datav, sampleindices) 
  
{
  d <- datav[sampleindices] # we will use this for bootstrapping
  return( mean(d) )
}

## Bootstrapping with 10000 replications
results <- boot(data=as.vector(ObservedHeights), statistic=ReturnMean, R=10000)


hist(results$t)
results



```


```{r plot topic year, eval=FALSE, include=FALSE}
#-----------------Topic-----------------------
topics = c('Business','Social.Media','Technology','Influence','Application','Aversion')


for (i in 1:length(topics)){
  
  summ.cumm %>% 
    filter(Topic==topics[i]) %>%
    with(plot(Year, Sent, main =topics[i],xlab = 'Analyzed Year', ylab = 'Tweets'))
  summ.cumm %>% 
    filter(Topic==topics[i]) %>% 
    with(lines(unique(Year), Sent[VADERclass=='Positive'], col = 3) )
  summ.cumm %>% 
    filter(Topic==topics[i]) %>%
    with(lines(unique(Year), Sent[VADERclass=='Neutral'], col = 1))
  summ.cumm %>% 
    filter(Topic==topics[i]) %>%
    with(lines(unique(Year), Sent[VADERclass=='Negative'], col = 2))
  summ.cumm %>% 
    filter(Topic==topics[i]) %>%
    with(lines(unique(Year), Sent[VADERclass=='Aversive'], col = 4))
  summ.cumm %>% 
    filter(Topic==topics[i]) %>%
    with(legend("topright", legend=c("neutral", "positive", "negative", "aversive"), col=c("black","green", "red"), lty=1:1, cex=0.8)) 
}
```


## Progression over the years

The diagram shows the percentage progression of the results of the sentiment analysis of tweets over the years 2010 to 2021. Values between 0.3 and -0.3 were classified as neutral. As positive between 0.3 and 1, as negative between -0.3 and -0.7 and finally as aversive values between -0.7 and -1. A total of 143271 tweets were analyzed. The fewest tweets were aversive and most were neutral since all tweets not evaluated in the sentiment analysis are classified as neutral. 
```{r yearplot, echo=FALSE, warning=FALSE}
plot(summ.year$Year, summ.year$percent, main ="Progression over the years",xlab = 'Analyzed year', ylab = 'Percent',cex.lab=1, cex.axis=1, cex.main=2, cex.sub=1)
lines(unique(summ.year$Year), summ.year$percent[summ.year$VADERclass=='Positive'], col = "green", lwd=2)
lines(unique(summ.year$Year), summ.year$percent[summ.year$VADERclass=='Neutral'], col = "black", lwd=2)
lines(unique(summ.year$Year), summ.year$percent[summ.year$VADERclass=='Negative'], col = "blue", lwd=2)
lines(unique(summ.year$Year), summ.year$percent[summ.year$VADERclass=='Aversive'], col = "red",lwd=2)
legend("topright", legend=c("positive", "neutral", "negative", "aversive"), col=c("green","black", "blue", "red"), lty=1:1,lwd=2, cex=.7)
```

Over time, the number of neutral tweets decreases. In 2010, there were 6934 tweets and 58.3%. In 2015, the most neutral tweets were posted with an absolute of 7641 tweets and 63.8% posted. In 2019 the fewest mi 5241 and 43.7% were posted. 2021 total 5254 which is 43.8%. The last 3 years the number of neutral tweets remained at the same level. 

An increasing trend can be seen in the number of positive tweets. In 2010, there were 3827 tweets and 32.2%. In 2019, the most positive tweets were posted with absolute 4878 tweets and 40.7% posted. In 2011 the least mi 3171 and 26.7% were posted. 2021 total 4868 which is 40.6%. The last 3 years the number of positive tweets remained high, with a bump in 2020 with 3908 and 32.6%.

Negative tweets show an increasing trend. In 2010, there were 1008 tweets and 8.5%. In 2020 the most positive tweets were posted with absolute 1867 tweets and 15.6% posted. In 2015 the least mi 918 and 7.7% were posted. In 2021 a total of 1429 which gives 11.9%. 

The aversive tweets behave similarly to the negative tweets 2011 113 0.95% there were the fewest were 2014 105 and 0.88% with the most there were 2020 968 8.1% and 2021 there were 3.7% and 449 tweets.

## Distribution of classes by topic

This graph shows the different topics, Business, Social Media, Technology, Immutability, Influence, Application and Aversion as well as the percentage distribution cer VADER classes Aversive Negative Neutral and Positive.


```{r topicplot,echo=FALSE}

ggplot(data=summ.topic, 
       aes(x=Topic, y=percent, fill=VADERclass)) + 
  ggtitle("Topics 2010-2021") +
  geom_bar(stat="identity", position=position_dodge(), colour="black")+
  theme(axis.text=element_text(size=8),plot.title = element_text(color="Black", size=6, face="bold", hjust = 0.5),
        legend.text=element_text(size=6),
  axis.title=element_text(size=8,face="bold"))

```
```{r conf, include=FALSE}
# Bootstrap 95% CI for R-Squared
boot.ci(results, type="bca")
```

The topic Aversion has the most aversive tweets with 16.8% and 35% negative tweets, so there are more negative tweets in this topic than positive 20%. The least in Application here there are no negative tweets at all. In the topic Social media 28.9% of the tweets are positive 13.6% negative and 3.7% aversive. In total, there were also the most tweets in this topic with a total of 42020.


# Conclusion: 


# Critique: Alina


# Github Repository

https://github.com/sonnleit/AlgorithmAversion



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
#summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
#plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

# Header 1
## Header 2
### Header 3
#### Header 4
##### Header 5
###### Header 6







```{r cars4}


```

```{r cars5}

```

